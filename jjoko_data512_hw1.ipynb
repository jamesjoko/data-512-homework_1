{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7fb43cd",
   "metadata": {},
   "source": [
    "# Homework 1 - Professionalism & Reproducibility\n",
    "# Name: James Joko (jjoko)\n",
    "\n",
    "## License\n",
    "The \"CONSTANTS\" cell, the `request_pageviews_per_article_mobile` function, and the `request_pageviews_per_article_desktop` function in this notebook contains code developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the Creative Commons [CC-BY license](https://creativecommons.org/licenses/by/4.0/). The following changes were made: REQUEST_HEADERS uses my UW email for the 'User-Agent', ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE has been changed to match the time range desired by the assignment and access types required by each question, the `request_pageviews_per_article_mobile` makes one request for each mobile type and sums the respon\n",
    "\n",
    "For reproducibility, execute each cell from top to bottom. The file \"thank_the_academy.AUG.2023.csv\" must be located in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3be29",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Import the necessary modules we need for this homework. JSON for reading and storing API output, time for adding an artificial delay, urllib for URI encoding article titles, requests to make API requests, and pandas for reading the article dataset. We also load the article dataset into memory and define any constants we need for the API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af701706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, urllib.parse, requests, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ca039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Everything_Every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Quiet on the Western Front (2022 film)</td>\n",
       "      <td>https://en.wikipedia.org/wiki/All_Quiet_on_the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Whale (2022 film)</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Whale_(2022_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Top_Gun:_Maverick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther: Wakanda Forever</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Black_Panther:_W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  \\\n",
       "0           Everything Everywhere All at Once   \n",
       "1  All Quiet on the Western Front (2022 film)   \n",
       "2                       The Whale (2022 film)   \n",
       "3                           Top Gun: Maverick   \n",
       "4              Black Panther: Wakanda Forever   \n",
       "\n",
       "                                                 url  \n",
       "0  https://en.wikipedia.org/wiki/Everything_Every...  \n",
       "1  https://en.wikipedia.org/wiki/All_Quiet_on_the...  \n",
       "2  https://en.wikipedia.org/wiki/The_Whale_(2022_...  \n",
       "3    https://en.wikipedia.org/wiki/Top_Gun:_Maverick  \n",
       "4  https://en.wikipedia.org/wiki/Black_Panther:_W...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(\"thank_the_academy.AUG.2023.csv\")\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55788b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': 'jjoko@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"mobile-app\",\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015060100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023093024\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f50b88",
   "metadata": {},
   "source": [
    "# Step 1: Data Acquisition\n",
    "## 1. Monthly Mobile Access\n",
    "To calculate monthly mobile access I make two requests for each article, one for each access type of mobile. I then sum the two outputs, remove the access field, and return the output as {article_title: \\<time series data\\>}. Once this process has been executed on all articles in the dataset, I save the output to a JSON file and verify the files structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"mobile-app\",\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015060100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023093024\"    \n",
    "}\n",
    "\n",
    "def request_pageviews_per_article_mobile(article_title = None, \n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'), safe='')\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # Run a request for each mobile access type and store them\n",
    "    mobile_access = [\"mobile-app\", \"mobile-web\"]\n",
    "    json_response = []\n",
    "\n",
    "    for access in mobile_access:\n",
    "        request_template[\"access\"] = access\n",
    "        \n",
    "        # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "        request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "\n",
    "        # make the request\n",
    "        try:\n",
    "            # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "            # occurs during the request processing - throttling is always a good practice with a free\n",
    "            # data source like Wikipedia - or other community sources\n",
    "            if API_THROTTLE_WAIT > 0.0:\n",
    "                time.sleep(API_THROTTLE_WAIT)\n",
    "            response = requests.get(request_url, headers=headers)\n",
    "            json_response.append(response.json())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    # post-process the mobile json requests: sum the user counts, remove the access field\n",
    "    for idx, item in enumerate(json_response[0][\"items\"]):\n",
    "        del item[\"access\"]\n",
    "        item[\"views\"] += json_response[1][\"items\"][idx][\"views\"]\n",
    "    return {article_title: json_response[0][\"items\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe98b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_mobile = {}\n",
    "for article_title in articles[\"name\"]:\n",
    "    print(article_title)\n",
    "    monthly_mobile.update(request_pageviews_per_article_mobile(article_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_mobile_201506-202309.json', 'w') as file:\n",
    "    json.dump(monthly_mobile, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_mobile_201506-202309.json', 'r') as file:\n",
    "    print(json.load(file)[\"Everything Everywhere All at Once\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed586e",
   "metadata": {},
   "source": [
    "## 2. Monthly Desktop Access\n",
    "To calculate monthly desktop access I make a signle request for each article, specifying dekstop access. I then remove the access field and return the output as {article_title: \\<time series data\\>}. Once this process has been executed on all articles in the dataset, I save the output to a JSON file and verify the files structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"desktop\",\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015060100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023093024\"    \n",
    "}\n",
    "\n",
    "def request_pageviews_per_article_desktop(article_title = None, \n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'), safe='')\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = {article_title: response.json()[\"items\"]}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_desktop = {}\n",
    "for article_title in articles[\"name\"]:\n",
    "    monthly_desktop.update(request_pageviews_per_article_desktop(article_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a06cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_desktop_201506-202309.json', 'w') as file:\n",
    "    json.dump(monthly_desktop, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2aad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_desktop_201506-202309.json', 'r') as file:\n",
    "    print(json.load(file)[\"Everything Everywhere All at Once\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c8f96",
   "metadata": {},
   "source": [
    "## 3. Monthly Cumulative\n",
    "I already have the monthly time series of both mobile and desktop traffic per article. Firstly, I created a deepcopy of the monthly mobile traffic. Then, for every article, I start at the first month in the time series and add the desktop views to the mobile views for that month. After, I add the previous month's cumulative total to the views. Once this has been completed for each article, I write the resulting dictionary to storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "with open('academy_monthly_mobile_201506-202309.json', 'r') as file:\n",
    "    monthly_mobile = json.load(file)\n",
    "with open('academy_monthly_desktop_201506-202309.json', 'r') as file:\n",
    "    monthly_desktop = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e97d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_cumulative = deepcopy(monthly_mobile)\n",
    "for article_title in monthly_cumulative.keys():\n",
    "    prev_views = 0\n",
    "    for idx, month in enumerate(monthly_cumulative[article_title]):\n",
    "        month[\"views\"] += monthly_desktop[article_title][idx][\"views\"]\n",
    "        month[\"views\"] += prev_views\n",
    "        prev_views = month[\"views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152de32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_cumulative_201506-202309.json', 'w') as file:\n",
    "    json.dump(monthly_cumulative, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('academy_monthly_cumulative_201506-202309.json', 'r') as file:\n",
    "    print(json.load(file)[\"Everything Everywhere All at Once\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54838103",
   "metadata": {},
   "source": [
    "# Step 2: Analysis\n",
    "For the analysis, I import matplotlib for time series visualization and datetime to properly format the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a07b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c73c1c",
   "metadata": {},
   "source": [
    "## Maximum Average and Minimum Average\n",
    "To get the minimum and maximum average for each access type, I sum the views field of the time series and divide it by the length of the time series. If the average is greater than the max average seen so far or less than the min average seen so far, I save the article title and the average monthly views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_avg_desktop = (None, -1)\n",
    "min_avg_desktop = (None, float(\"inf\"))\n",
    "for article_title in monthly_desktop.keys():\n",
    "    avg_views = sum(month[\"views\"] for month in monthly_desktop[article_title]) / len(monthly_desktop[article_title])\n",
    "    if avg_views > max_avg_desktop[1]:\n",
    "        max_avg_desktop = (article_title, avg_views)\n",
    "    if avg_views < min_avg_desktop[1]:\n",
    "        min_avg_desktop = (article_title, avg_views)\n",
    "print(f\"Maximum Average Desktop: {max_avg_desktop}\")\n",
    "print(f\"Minimum Average Desktop: {min_avg_desktop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_avg_mobile = (None, -1)\n",
    "min_avg_mobile = (None, float(\"inf\"))\n",
    "for article_title in monthly_mobile.keys():\n",
    "    avg_views = sum(month[\"views\"] for month in monthly_mobile[article_title]) / len(monthly_mobile[article_title])\n",
    "    if avg_views > max_avg_mobile[1]:\n",
    "        max_avg_mobile = (article_title, avg_views)\n",
    "    if avg_views < min_avg_mobile[1]:\n",
    "        min_avg_mobile = (article_title, avg_views)\n",
    "print(f\"Maximum Average Mobile: {max_avg_mobile}\")\n",
    "print(f\"Minimum Average Mobile: {min_avg_mobile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1520d1",
   "metadata": {},
   "source": [
    "To visualize the time series, I convert the timestamps to datetimes for x coordinates and views as the y coordinates for each of the min/max average per access type. I then specify axis labels and a correct y-axis scale to view all of the data. Without the log scale, pages with a low number of monthly views are overlapping lines at the bottom of the visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc73593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "plt.xticks(rotation=-70)\n",
    "plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_desktop[max_avg_desktop[0]]], [month[\"views\"] for month in monthly_desktop[max_avg_desktop[0]]], label=\"Maximum Average Desktop: \" + max_avg_desktop[0])\n",
    "plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_desktop[min_avg_desktop[0]]], [month[\"views\"] for month in monthly_desktop[min_avg_desktop[0]]], label=\"Minimum Average Desktop: \" + min_avg_desktop[0])\n",
    "plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_mobile[max_avg_mobile[0]]], [month[\"views\"] for month in monthly_mobile[max_avg_mobile[0]]], label=\"Maximum Average Mobile: \" + max_avg_mobile[0])\n",
    "plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_mobile[min_avg_mobile[0]]], [month[\"views\"] for month in monthly_mobile[min_avg_mobile[0]]], label=\"Minimum Average Mobile: \" + min_avg_mobile[0])\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Log Number of Monthly Views\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.title(\"Monthly Wikipedia Article Views over Time of Academy Award Winning Films with the Maximum and Minimum Average Monthly Views per Access Type\")\n",
    "plt.savefig(\"max_and_min_average.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5361d",
   "metadata": {},
   "source": [
    "## Top 10 Peak Page Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b95ce",
   "metadata": {},
   "source": [
    "To get the 10 articles with the highest peak page views per access type, I made a dictionary of the high peak page views per article per access type, sorted the dictionaries by descending value, and saved the article titles of the 10 highest peak page views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b54185",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_views_mobile = {}\n",
    "peak_views_desktop = {}\n",
    "for article_title in monthly_mobile.keys():\n",
    "    peak_views_mobile[article_title] = max(month[\"views\"] for month in monthly_mobile[article_title])\n",
    "    peak_views_desktop[article_title] = max(month[\"views\"] for month in monthly_desktop[article_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c067ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_mobile = sorted(peak_views_mobile, key=peak_views_mobile.get, reverse=True)[:10]\n",
    "top_10_desktop = sorted(peak_views_desktop, key=peak_views_desktop.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971daec",
   "metadata": {},
   "source": [
    "To visualize the time series, I convert the timestamps to datetimes for x coordinates and views as the y coordinates for each of the 10 articles with peak page views per access type. I then specify axis labels and a correct y-axis scale to view all of the data. Without the log scale, pages with a low number of monthly views are overlapping lines at the bottom of the visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,7)\n",
    "plt.xticks(rotation=-70)\n",
    "for article_title in top_10_desktop:\n",
    "    plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_desktop[article_title]], [month[\"views\"] for month in monthly_desktop[article_title]], label=\"Desktop: \" + article_title)\n",
    "for article_title in top_10_mobile:\n",
    "    plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_mobile[article_title]], [month[\"views\"] for month in monthly_mobile[article_title]], label=\"Mobile: \" + article_title)\n",
    "plt.legend(loc = 6, bbox_to_anchor=(1, 0.5))\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Log Number of Monthly Views\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.title(\"Monthly Wikipedia Article Views over Time of the Top 10 Academy Award Winning Films by Peak Page Views per Access Type\")\n",
    "plt.savefig(\"top10_peak_page_views.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8cd4b",
   "metadata": {},
   "source": [
    "## Fewest Months of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0792f8",
   "metadata": {},
   "source": [
    "To get the 10 articles with the fewest months of data per access type, I made a dictionary of the number of months (the length of the time series returned by the API) per article per access type, sorted the dictionaries by ascending value, and saved the article titles of the 10 fewest months of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_months_mobile = {}\n",
    "num_months_desktop = {}\n",
    "for article_title in monthly_mobile.keys():\n",
    "    num_months_mobile[article_title] = len(monthly_mobile[article_title])\n",
    "    num_months_desktop[article_title] = len(monthly_desktop[article_title])\n",
    "recent_10_mobile = sorted(num_months_mobile, key=num_months_mobile.get)[:10]\n",
    "recent_10_desktop = sorted(num_months_desktop, key=num_months_desktop.get)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9071591",
   "metadata": {},
   "source": [
    "To visualize the time series, I convert the timestamps to datetimes for x coordinates and views as the y coordinates for each of the 10 articles with the fewest months of data per access type. I then specify axis labels and a correct y-axis scale to view all of the data. Without the log scale, pages with a low number of monthly views are overlapping lines at the bottom of the visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97140d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,7)\n",
    "plt.xticks(rotation=-70)\n",
    "for article_title in recent_10_desktop:\n",
    "    plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_desktop[article_title]], [month[\"views\"] for month in monthly_desktop[article_title]], label=\"Desktop: \" + article_title)\n",
    "for article_title in recent_10_mobile:\n",
    "    plt.plot([datetime.strptime(month[\"timestamp\"], \"%Y%m%d%H\") for month in monthly_mobile[article_title]], [month[\"views\"] for month in monthly_mobile[article_title]], label=\"Mobile: \" + article_title)\n",
    "plt.legend(loc = 6, bbox_to_anchor=(1, 0.5))\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Log Number of Monthly Views\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.title(\"Monthly Wikipedia Article Views over Time of the Academy Award Winning Films with the Fewest Months of Data per Access Type\")\n",
    "plt.savefig(\"fewest_months_of_data.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
